{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9b2f8f",
   "metadata": {},
   "source": [
    "# Spectral Super Resolution with Cross-Modal Diffusion Models\n",
    "\n",
    "This notebook demonstrates a simplified version of a model inspired by [this paper](https://arxiv.org/abs/2310.03024). We generate synthetic galaxy images and spectra, train encoders with a contrastive loss, and add a diffusion-based decoder to generate spectra conditioned on the image latent representation.\n",
    "\n",
    "Enjoy the cosmic ride with some code magic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384aebf1",
   "metadata": {},
   "source": [
    "## 1. Synthetic Data Generation\n",
    "\n",
    "In this section, we generate synthetic galaxy images and spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "def generate_synthetic_galaxy_image():\n",
    "    \"\"\"\n",
    "    Generates a synthetic 64x64 grayscale image with a single Gaussian blob,\n",
    "    mimicking a galaxy.\n",
    "    \"\"\"\n",
    "    image = np.zeros((64, 64), dtype=np.float32)\n",
    "    x_center = np.random.randint(20, 44)\n",
    "    y_center = np.random.randint(20, 44)\n",
    "    xv, yv = np.meshgrid(np.arange(64), np.arange(64))\n",
    "    sigma = np.random.uniform(3, 8)\n",
    "    blob = np.exp(-((xv - x_center)**2 + (yv - y_center)**2) / (2 * sigma**2))\n",
    "    image += blob\n",
    "    image = image / image.max()\n",
    "    return image\n",
    "\n",
    "def generate_synthetic_spectrum():\n",
    "    \"\"\"\n",
    "    Generates a synthetic 1D spectrum over wavelengths 400-800 nm with a few Gaussian peaks\n",
    "    (e.g., H-alpha near 656 nm) plus noise.\n",
    "    \"\"\"\n",
    "    wavelengths = np.linspace(400, 800, 1000)  # in nm\n",
    "    spectrum = np.zeros_like(wavelengths)\n",
    "    peaks = [500, 656, 700]\n",
    "    for peak in peaks:\n",
    "        amplitude = np.random.uniform(0.5, 1.0)\n",
    "        sigma = np.random.uniform(5, 15)\n",
    "        spectrum += amplitude * np.exp(-0.5 * ((wavelengths - peak) / sigma)**2)\n",
    "    noise = np.random.normal(0, 0.05, size=wavelengths.shape)\n",
    "    spectrum += noise\n",
    "    spectrum = (spectrum - spectrum.min()) / (spectrum.max() - spectrum.min())\n",
    "    return wavelengths, spectrum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2193b9a4",
   "metadata": {},
   "source": [
    "## 2. Dataset Definition\n",
    "\n",
    "We create a custom PyTorch Dataset that generates pairs of synthetic galaxy images and spectra on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d36fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, num_samples=200):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = generate_synthetic_galaxy_image()  # (64,64)\n",
    "        _, spectrum = generate_synthetic_spectrum()  # (1000,)\n",
    "        image = np.expand_dims(image, axis=0)  # Add channel dimension\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        spectrum = torch.tensor(spectrum, dtype=torch.float32)\n",
    "        return image, spectrum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3116ab",
   "metadata": {},
   "source": [
    "## 3. Model Definitions\n",
    "\n",
    "We define our image and spectrum encoders. These are simple architectures that compress the input data into a shared latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),  # 32x32\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class SpectrumEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(SpectrumEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1000, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, embedding_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1f813",
   "metadata": {},
   "source": [
    "## 4. Dummy Diffusion Process and Contrastive Loss\n",
    "\n",
    "We simulate a forward diffusion process by adding Gaussian noise and define a contrastive loss\n",
    "that aligns the image and spectrum latent spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_diffusion(x, t):\n",
    "    \"\"\"\n",
    "    A dummy diffusion function that adds Gaussian noise to simulate a diffusion step.\n",
    "    The noise level is proportional to the time step 't'.\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x) * (t / 10.0)\n",
    "    return x + noise\n",
    "\n",
    "def contrastive_loss(image_embeddings, spectrum_embeddings, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Computes an InfoNCE loss that aligns image and spectrum embeddings.\n",
    "    \"\"\"\n",
    "    batch_size = image_embeddings.shape[0]\n",
    "    image_norm = image_embeddings / image_embeddings.norm(dim=1, keepdim=True)\n",
    "    spectrum_norm = spectrum_embeddings / spectrum_embeddings.norm(dim=1, keepdim=True)\n",
    "    logits = torch.mm(image_norm, spectrum_norm.t()) / temperature\n",
    "    labels = torch.arange(batch_size).to(logits.device)\n",
    "    loss_i = nn.CrossEntropyLoss()(logits, labels)\n",
    "    loss_s = nn.CrossEntropyLoss()(logits.t(), labels)\n",
    "    loss = (loss_i + loss_s) / 2\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2e50df",
   "metadata": {},
   "source": [
    "## 5. Training Setup\n",
    "\n",
    "We set hyperparameters, create the dataset and dataloader, and instantiate our encoders and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "dataset = GalaxyDataset(num_samples=200)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_encoder = ImageEncoder(embedding_dim=embedding_dim).to(device)\n",
    "spectrum_encoder = SpectrumEncoder(embedding_dim=embedding_dim).to(device)\n",
    "\n",
    "optimizer = optim.Adam(list(image_encoder.parameters()) + list(spectrum_encoder.parameters()), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd442e96",
   "metadata": {},
   "source": [
    "## 6. Training Loop\n",
    "\n",
    "We train the model by adding noise to the inputs (simulating diffusion), encoding them, and\n",
    "optimizing a contrastive loss between the modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3559e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training... (May the cosmic forces be with you!)\")\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for image, spectrum in dataloader:\n",
    "        image = image.to(device)\n",
    "        spectrum = spectrum.to(device)\n",
    "        t = random.uniform(0, 1)\n",
    "        image_noisy = apply_diffusion(image, t)\n",
    "        spectrum_noisy = apply_diffusion(spectrum, t)\n",
    "        \n",
    "        img_emb = image_encoder(image_noisy)\n",
    "        spec_emb = spectrum_encoder(spectrum_noisy)\n",
    "        \n",
    "        loss = contrastive_loss(img_emb, spec_emb)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete! Your model has begun to decode the cosmic secrets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b221d66",
   "metadata": {},
   "source": [
    "## 7. Visualization of Synthetic Data\n",
    "\n",
    "We visualize one example of a synthetic galaxy image and its corresponding spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, spectrum = dataset[0]\n",
    "wavelengths = np.linspace(400, 800, 1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].imshow(image.squeeze(), cmap=\"gray\")\n",
    "ax[0].set_title(\"Synthetic Galaxy Image\")\n",
    "ax[1].plot(wavelengths, spectrum.numpy())\n",
    "ax[1].set_title(\"Synthetic Spectrum\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9918e86",
   "metadata": {},
   "source": [
    "## 8. Diffusion Decoder for Spectrum Generation\n",
    "\n",
    "We add a conditional diffusion-based spectrum generator. This module denoises a noisy spectrum,\n",
    "conditioned on the image latent vector. We then define a reverse diffusion process to generate\n",
    "a spectrum starting from random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrumDiffusionDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, spectrum_dim=1000):\n",
    "        super(SpectrumDiffusionDecoder, self).__init__()\n",
    "        # A simple MLP that conditions on both the noisy spectrum and the image latent\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(spectrum_dim + embedding_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, spectrum_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, noisy_spectrum, image_latent):\n",
    "        # Expand image latent to match batch size if needed and concatenate with the noisy spectrum.\n",
    "        cond = image_latent.expand(noisy_spectrum.size(0), -1)\n",
    "        x = torch.cat([noisy_spectrum, cond], dim=1)\n",
    "        return self.net(x)\n",
    "\n",
    "def reverse_diffusion(image_latent, diffusion_decoder, steps=10, spectrum_dim=1000):\n",
    "    \"\"\"\n",
    "    A dummy reverse diffusion process.\n",
    "    Starting from pure noise, iteratively refine the spectrum using the diffusion decoder,\n",
    "    conditioned on the image latent.\n",
    "    \"\"\"\n",
    "    # Start with an initial random noise spectrum.\n",
    "    x = torch.randn(1, spectrum_dim).to(image_latent.device)\n",
    "    step_size = 1.0 / steps\n",
    "    for step in reversed(range(1, steps + 1)):\n",
    "        # In a real diffusion model, the network predicts the noise; here we simulate by a direct update.\n",
    "        noise_estimate = diffusion_decoder(x, image_latent)\n",
    "        # Update: subtract a fraction of the predicted noise to denoise.\n",
    "        x = x - step_size * noise_estimate\n",
    "    return x\n",
    "\n",
    "def generate_spectrum_via_diffusion(image, image_encoder, diffusion_decoder, steps=10):\n",
    "    \"\"\"\n",
    "    Generates a spectrum for a given galaxy image using a reverse diffusion process.\n",
    "    The image is encoded to obtain its latent representation, which then conditions the diffusion decoder.\n",
    "    \"\"\"\n",
    "    # Ensure the image has shape (batch_size, channels, height, width)\n",
    "    image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        # Obtain the latent representation of the input image\n",
    "        image_latent = image_encoder(image_tensor)\n",
    "        # Run the reverse diffusion process to generate a spectrum\n",
    "        generated_spectrum = reverse_diffusion(image_latent, diffusion_decoder, steps=steps)\n",
    "    return generated_spectrum\n",
    "\n",
    "# Instantiate the diffusion decoder (note: it is not trained in this dummy demo)\n",
    "spectrum_diffusion_decoder = SpectrumDiffusionDecoder(embedding_dim=embedding_dim, spectrum_dim=1000).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d94cc4",
   "metadata": {},
   "source": [
    "## 9. Generate and Visualize Spectrum from Dummy Galaxy\n",
    "\n",
    "We generate a new dummy galaxy image, then use our diffusion decoder to generate a spectrum\n",
    "conditioned on the image latent representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new dummy galaxy image\n",
    "dummy_image = generate_synthetic_galaxy_image()\n",
    "\n",
    "# Use the diffusion decoder to generate a spectrum conditioned on the image latent\n",
    "generated_spec = generate_spectrum_via_diffusion(dummy_image, image_encoder, spectrum_diffusion_decoder, steps=10)\n",
    "\n",
    "# Visualization of the dummy galaxy and its generated spectrum via diffusion\n",
    "wavelengths = np.linspace(400, 800, 1000)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax[0].imshow(dummy_image, cmap=\"gray\")\n",
    "ax[0].set_title(\"Dummy Galaxy Image\")\n",
    "ax[1].plot(wavelengths, generated_spec.cpu().numpy().squeeze())\n",
    "ax[1].set_title(\"Diffusion-Generated Spectrum\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
