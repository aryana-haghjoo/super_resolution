{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [0/32], Loss: 4.5226\n",
      "Epoch [1/10], Batch [10/32], Loss: 4.5312\n",
      "Epoch [1/10], Batch [20/32], Loss: 4.4677\n",
      "Epoch [1/10], Batch [30/32], Loss: 4.4240\n",
      "Epoch [1/10] Average Loss: 4.4883\n",
      "Epoch [2/10], Batch [0/32], Loss: 4.4069\n",
      "Epoch [2/10], Batch [10/32], Loss: 4.4066\n",
      "Epoch [2/10], Batch [20/32], Loss: 4.3745\n",
      "Epoch [2/10], Batch [30/32], Loss: 4.2908\n",
      "Epoch [2/10] Average Loss: 4.3264\n",
      "Epoch [3/10], Batch [0/32], Loss: 4.3100\n",
      "Epoch [3/10], Batch [10/32], Loss: 4.2808\n",
      "Epoch [3/10], Batch [20/32], Loss: 4.2502\n",
      "Epoch [3/10], Batch [30/32], Loss: 4.2515\n",
      "Epoch [3/10] Average Loss: 4.2357\n",
      "Epoch [4/10], Batch [0/32], Loss: 4.2232\n",
      "Epoch [4/10], Batch [10/32], Loss: 4.1993\n",
      "Epoch [4/10], Batch [20/32], Loss: 4.1984\n",
      "Epoch [4/10], Batch [30/32], Loss: 4.2005\n",
      "Epoch [4/10] Average Loss: 4.1609\n",
      "Epoch [5/10], Batch [0/32], Loss: 4.1441\n",
      "Epoch [5/10], Batch [10/32], Loss: 4.1063\n",
      "Epoch [5/10], Batch [20/32], Loss: 4.1141\n",
      "Epoch [5/10], Batch [30/32], Loss: 4.1622\n",
      "Epoch [5/10] Average Loss: 4.1256\n",
      "Epoch [6/10], Batch [0/32], Loss: 4.1517\n",
      "Epoch [6/10], Batch [10/32], Loss: 4.1020\n",
      "Epoch [6/10], Batch [20/32], Loss: 4.0877\n",
      "Epoch [6/10], Batch [30/32], Loss: 4.0871\n",
      "Epoch [6/10] Average Loss: 4.0920\n",
      "Epoch [7/10], Batch [0/32], Loss: 4.1987\n",
      "Epoch [7/10], Batch [10/32], Loss: 4.1322\n",
      "Epoch [7/10], Batch [20/32], Loss: 4.0807\n",
      "Epoch [7/10], Batch [30/32], Loss: 4.1004\n",
      "Epoch [7/10] Average Loss: 4.0793\n",
      "Epoch [8/10], Batch [0/32], Loss: 4.1330\n",
      "Epoch [8/10], Batch [10/32], Loss: 4.0665\n",
      "Epoch [8/10], Batch [20/32], Loss: 4.1192\n",
      "Epoch [8/10], Batch [30/32], Loss: 4.1665\n",
      "Epoch [8/10] Average Loss: 4.0652\n",
      "Epoch [9/10], Batch [0/32], Loss: 4.1700\n",
      "Epoch [9/10], Batch [10/32], Loss: 4.1284\n",
      "Epoch [9/10], Batch [20/32], Loss: 4.1353\n",
      "Epoch [9/10], Batch [30/32], Loss: 4.1208\n",
      "Epoch [9/10] Average Loss: 4.0571\n",
      "Epoch [10/10], Batch [0/32], Loss: 4.1160\n",
      "Epoch [10/10], Batch [10/32], Loss: 4.0468\n",
      "Epoch [10/10], Batch [20/32], Loss: 4.0995\n",
      "Epoch [10/10], Batch [30/32], Loss: 4.1692\n",
      "Epoch [10/10] Average Loss: 4.0423\n",
      "Training complete! May your galaxies shine bright and your spectra be ever detailed.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# =============================================================================\n",
    "# Dummy Dataset\n",
    "# =============================================================================\n",
    "# Our simulated dataset creates random \"galaxy images\" and corresponding spectra.\n",
    "# In real-life, your data might be as elusive as a galaxy in a dark sky,\n",
    "# but here we generate random tensors for demonstration.\n",
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, num_samples=1000, image_size=(3, 64, 64), low_spec_length=100, high_spec_length=200):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.low_spec_length = low_spec_length\n",
    "        self.high_spec_length = high_spec_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Simulate a galaxy image (3-channel photometric image)\n",
    "        image = torch.randn(self.image_size)\n",
    "        # Simulate low-resolution (noisy) space-based spectrum (e.g., 3DHST GRISM)\n",
    "        low_res_spec = torch.randn(self.low_spec_length)\n",
    "        # Simulate high-resolution spectrum (e.g., Keck MOSDEF)\n",
    "        high_res_spec = torch.randn(self.high_spec_length)\n",
    "        return image, low_res_spec, high_res_spec\n",
    "\n",
    "# =============================================================================\n",
    "# Model Components\n",
    "# =============================================================================\n",
    "\n",
    "# Image Encoder: a simple CNN to extract features from galaxy images.\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # (3,64,64) -> (16,32,32)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # (16,32,32) -> (32,16,16)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # (32,16,16) -> (64,8,8)\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(64 * 8 * 8, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        embedding = self.fc(x)\n",
    "        return embedding\n",
    "\n",
    "# Spectrum Encoder: a simple MLP to extract features from 1D spectral data.\n",
    "class SpectrumEncoder(nn.Module):\n",
    "    def __init__(self, input_length, embedding_dim=128):\n",
    "        super(SpectrumEncoder, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_length, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, input_length)\n",
    "        embedding = self.net(x)\n",
    "        return embedding\n",
    "\n",
    "# Conditional Diffusion Model: a simplified network that predicts the noise component\n",
    "# added to the high-resolution spectrum, conditioned on the image embedding.\n",
    "class ConditionalDiffusionModel(nn.Module):\n",
    "    def __init__(self, spectrum_length, embedding_dim=128):\n",
    "        super(ConditionalDiffusionModel, self).__init__()\n",
    "        # Use a linear layer to project the image embedding to the spectrum dimension.\n",
    "        self.fc_cond = nn.Linear(embedding_dim, spectrum_length)\n",
    "        # A simple feedforward network to predict the noise.\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(spectrum_length, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, spectrum_length)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        # x: noisy high-resolution spectrum, shape (batch, spectrum_length)\n",
    "        # cond: image embedding, shape (batch, embedding_dim)\n",
    "        cond_proj = self.fc_cond(cond)  # Shape: (batch, spectrum_length)\n",
    "        # Add conditioning information in a simple additive way.\n",
    "        x_cond = x + cond_proj\n",
    "        predicted_noise = self.net(x_cond)\n",
    "        return predicted_noise\n",
    "\n",
    "# Contrastive Loss (InfoNCE) to align image and spectrum embeddings.\n",
    "# We want the matching image-spectrum pair to be more similar than non-matching pairs.\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.1):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, image_emb, spec_emb):\n",
    "        batch_size = image_emb.size(0)\n",
    "        # Normalize embeddings to unit length (for cosine similarity)\n",
    "        image_emb_norm = image_emb / image_emb.norm(dim=1, keepdim=True)\n",
    "        spec_emb_norm = spec_emb / spec_emb.norm(dim=1, keepdim=True)\n",
    "        # Compute the similarity matrix (batch_size x batch_size)\n",
    "        logits = torch.matmul(image_emb_norm, spec_emb_norm.T) / self.temperature\n",
    "        labels = torch.arange(batch_size, device=logits.device)\n",
    "        loss_i = self.cross_entropy(logits, labels)\n",
    "        loss_s = self.cross_entropy(logits.T, labels)\n",
    "        loss = (loss_i + loss_s) / 2\n",
    "        return loss\n",
    "\n",
    "# =============================================================================\n",
    "# Diffusion Noise Scheduler (Simplified)\n",
    "# =============================================================================\n",
    "# In full-fledged diffusion models, the noise schedule is more intricate.\n",
    "# Here, we assume a simple linear schedule to add noise to the high-res spectrum.\n",
    "def add_noise(x, noise, t):\n",
    "    # x_noisy = sqrt(1 - t) * x + sqrt(t) * noise\n",
    "    alpha = (1 - t).sqrt()\n",
    "    beta = t.sqrt()\n",
    "    return alpha * x + beta * noise\n",
    "\n",
    "# =============================================================================\n",
    "# Training Loop\n",
    "# =============================================================================\n",
    "def train(model_components, dataloader, device, num_epochs=10, diffusion_loss_weight=1.0):\n",
    "    image_encoder = model_components['image_encoder']\n",
    "    spectrum_encoder = model_components['spectrum_encoder']\n",
    "    diffusion_model = model_components['diffusion_model']\n",
    "    contrastive_loss_fn = model_components['contrastive_loss_fn']\n",
    "    \n",
    "    # Combine all model parameters in one optimizer\n",
    "    optimizer = optim.Adam(\n",
    "        list(image_encoder.parameters()) + \n",
    "        list(spectrum_encoder.parameters()) + \n",
    "        list(diffusion_model.parameters()), \n",
    "        lr=1e-3\n",
    "    )\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_idx, (image, low_res_spec, high_res_spec) in enumerate(dataloader):\n",
    "            image = image.to(device)\n",
    "            # Reshape spectra: (batch, spectrum_length)\n",
    "            low_res_spec = low_res_spec.to(device)\n",
    "            high_res_spec = high_res_spec.to(device)\n",
    "            \n",
    "            # Compute embeddings\n",
    "            img_emb = image_encoder(image)              # Image embedding: (batch, embedding_dim)\n",
    "            spec_emb = spectrum_encoder(high_res_spec)    # Spectrum embedding: (batch, embedding_dim)\n",
    "            \n",
    "            # Contrastive loss: Align the image and high-res spectrum embeddings.\n",
    "            contrast_loss = contrastive_loss_fn(img_emb, spec_emb)\n",
    "            \n",
    "            # Diffusion loss: Train the diffusion model to predict noise in high-res spectra.\n",
    "            batch_size = high_res_spec.size(0)\n",
    "            # Sample a random time t (between 0 and 1) for each sample in the batch.\n",
    "            t = torch.rand(batch_size, 1, device=device)\n",
    "            noise = torch.randn_like(high_res_spec)\n",
    "            # Generate a noisy high-resolution spectrum.\n",
    "            high_res_spec_noisy = add_noise(high_res_spec, noise, t)\n",
    "            # Predict the noise using the diffusion model conditioned on the image embedding.\n",
    "            noise_pred = diffusion_model(high_res_spec_noisy, img_emb)\n",
    "            diffusion_loss = mse_loss(noise_pred, noise)\n",
    "            \n",
    "            # Total loss: weighted sum of contrastive and diffusion losses.\n",
    "            total_loss = contrast_loss + diffusion_loss_weight * diffusion_loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += total_loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(dataloader)}], Loss: {total_loss.item():.4f}\")\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "    print(\"Training complete! May your galaxies shine bright and your spectra be ever detailed.\")\n",
    "\n",
    "# =============================================================================\n",
    "# Main Function\n",
    "# =============================================================================\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Hyperparameters\n",
    "    embedding_dim = 128\n",
    "    image_size = (3, 64, 64)\n",
    "    low_spec_length = 100\n",
    "    high_spec_length = 200  # High-resolution spectra are assumed to have twice the length.\n",
    "\n",
    "    # Instantiate model components.\n",
    "    image_encoder = ImageEncoder(embedding_dim=embedding_dim).to(device)\n",
    "    spectrum_encoder = SpectrumEncoder(input_length=high_spec_length, embedding_dim=embedding_dim).to(device)\n",
    "    diffusion_model = ConditionalDiffusionModel(spectrum_length=high_spec_length, embedding_dim=embedding_dim).to(device)\n",
    "    contrastive_loss_fn = ContrastiveLoss(temperature=0.1)\n",
    "    \n",
    "    model_components = {\n",
    "        'image_encoder': image_encoder,\n",
    "        'spectrum_encoder': spectrum_encoder,\n",
    "        'diffusion_model': diffusion_model,\n",
    "        'contrastive_loss_fn': contrastive_loss_fn\n",
    "    }\n",
    "    \n",
    "    # Create the dataset and dataloader.\n",
    "    dataset = GalaxyDataset(\n",
    "        num_samples=1000, \n",
    "        image_size=image_size, \n",
    "        low_spec_length=low_spec_length, \n",
    "        high_spec_length=high_spec_length\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Start training the model.\n",
    "    train(model_components, dataloader, device, num_epochs=10, diffusion_loss_weight=1.0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_reso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
